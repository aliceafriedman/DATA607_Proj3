---
title: "Data607_Proj3"
author: "Alice Friedman"
date: "October 16, 2018"
output:
  prettydoc::html_pretty:
    theme: leonids
    highlight: vignette
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Setup
```{r, results="hide", message=FALSE, warning=FALSE}
library(knitr)
library(kableExtra)
library(prettydoc)
library(RCurl)
library(dplyr)
library(ggplot2)
library(forcats)
library(varhandle)
library(stringr)
library(tidyr)
```

##Kaggle ML and Data Science Survey

Kaggle conducted a survey of more than 16,000 data scientists in 2017. Data used in the following analysis is pulled from https://www.kaggle.com/kaggle/kaggle-survey-2017.

```{r}
Kaggle.Multi <- read.csv("https://raw.githubusercontent.com/aliceafriedman/DATA607_Proj3/master/multipleChoiceResponses.csv", sep=",", header = TRUE)
```

####How much time do you spend on the following types of tasks?
One way to evaluate how much valuable different data science skills are is to determine how much time people spend using them.

The following analysis shows that for the survey respondents as a whole, the most important skills are: 
1. Gathering data

2. Model building

3. Visualizing data

4. Finding insights

5. Putting work into production (e.g. running versioning control)


```{r}
timeSpent <- Kaggle.Multi %>% 
  select(
  TimeGatheringData,
  TimeModelBuilding,
  TimeProduction,
  TimeVisualizing,
  TimeFindingInsights,
  TimeOtherSelect) %>% 
  rename(
  'Gathering Data' = TimeGatheringData,
  'Modeling' = TimeModelBuilding,
  'Production' = TimeProduction,
  'Visualizing' = TimeVisualizing,
  'Finding Insights' = TimeFindingInsights,
  'Other' = TimeOtherSelect) %>% 
  gather(key = "Skill", value = "PercTimeSpent", na.rm = TRUE) %>% glimpse()
  
timeSpent %>% 
  group_by(Skill) %>% 
  summarize("avg" = mean(PercTimeSpent), "Median % Time Spent"= median(PercTimeSpent)) %>% 
  arrange(desc(avg)) %>% 
  rename('Average % Time Spent' = avg) %>% 
  kable(digits = 0) %>% 
  kable_styling(bootstrap_options = "responsive")



```
  
###At work, what proportion of your analytics projects incorporate data visualization?	
Another way to determine how important a particular skill is to data scientsists is to look at how much of working data scientists' job uses that skill. One question the survey asks is, "At work, what proportion of your analytics projects incorporate data visualization?"

As the analysis shows below, the largest number of response by far is that more than three-quarters of all the respondents's assigned projects incorporate data visualization. Although the median response is that only 10\% of time is spent on this skill, data visualization must be an imrportant skill nonetheless!


```{r}
PercOrder <- c(
"None",
"10-25% of projects",
"26-50% of projects",
"51-75% of projects",
"76-99% of projects",
"100% of projects")

Kaggle.Multi$WorkDataVisualizations <- factor(Kaggle.Multi$WorkDataVisualizations, PercOrder)

Kaggle.Multi %>% 
  filter(WorkDataVisualizations!="") %>%
  mutate(WorkDataVisualizations = fct_recode(WorkDataVisualizations,
    "10-25%" = "10-25% of projects",
    "26-50%" = "26-50% of projects",
    "51-75%" = "51-75% of projects",
    "76-100%" = "76-99% of projects",
    "76-100%" = "100% of projects"
  )) %>% 
  ggplot(aes(WorkDataVisualizations))+
  geom_bar(aes(fill=WorkDataVisualizations))+
  theme(axis.text.x=element_text(angle = 60, hjust = 1))+
  labs(title = "At work, what proportion of your analytics projects\n incorportate data visualizations?",
       x = "Percent of Projects Incorporating Visualization",
       y = "Count")
```

###Who responded to this survey?

####Job Title
```{r}
Kaggle.Multi %>% 
  filter(CurrentJobTitleSelect!="") %>%
  mutate(CurrentJobTitleSelect = CurrentJobTitleSelect %>% fct_infreq() %>% fct_rev()) %>% 
  ggplot(aes(fct_relevel(CurrentJobTitleSelect, "Other")))+
  geom_bar(aes(fill=CurrentJobTitleSelect))+
  theme(axis.text.x=element_text(angle = 60, hjust = 1), legend.position="none")+
  labs(title = "Select the option that's most similar to your current job/professional \ntitle (or most recent title if retired)",
       x= "Job Title",
       y = "Count")
```

####Salary Data

This data requires a bit of munging, as salaries have been reported in several currencies, and a quick look at the repsonses seems to indicate that many individuals have entered there salaries in "thousands" whereas others have entered it in dollars. Some of the responses are in the millions. Are these liars, or just very well paid survey respondents?

To address the former, we will filter by responses reported in USD. To address the two latter, we have a options:

1. Ignore outliers (e.g. responses less than \$1000, and more than \$1,000,000)

2.  Assume that everyone is telling the truth about their salaries

3.  Assume that responses less than \$1000 are reporting in thousands (e.g. a response of $87 is intended to mean a salary of \$87,000, something which would be expected based on overall salary data for data scientists)

4. Some combination of the above, taking into account known salary distributions for particular titles.

The data munging to access US reported salaries also must take into account that data has been entered in a varirty of formats, resulting in data that cannot be easily converted to numeric.

First, let's investigate the data to see which of these options is most reasonable.

```{r}
USSalaries <- Kaggle.Multi %>% filter(CompensationCurrency=="USD") %>% 
  select(CompensationAmount) %>% 
#First, we must unfactor the data using the varhandle library
  mutate(CompensationAmount = unfactor(CompensationAmount), 
#Then, we must remove all commas, which are included in some, but not all, data entries before we can finally convert to numeric
         CompensationAmount = str_remove_all(CompensationAmount,","),
         CompensationAmount = as.numeric(CompensationAmount))
quantile(USSalaries[[1]], na.rm = TRUE)
```

The entry "9999999" seems obviously to be a false entry, and a number of the other outliers seems implausible as well. How many reported salaries are more than \$1M?

```{r}
USSalariesTest <- USSalaries %>% filter(USSalaries > 1000000)
USSalariesTest
```

Only 3! Seems plausible that 2 people out of more than 16,000 respondents could earn more than $1M, I will assume those are real entries. I will exclude the "9999999" entry, and rerun the results.

```{r}
USSalaries <- USSalaries %>% filter(USSalaries != 9999999)
quantile(USSalaries[[1]], na.rm = TRUE)
```

#####How many people report less than $1000 in salary?
```{r}
USSalariesTest2 <- USSalaries %>% filter(USSalaries >0 & USSalaries < 1000)
USSalariesTest2
```

Since the number of entries less than \$1000 is small (12), they will not meaningfully impact the analysis. We can proceed under the (possibly incorrect) assumption that all data except 9999999 is a valid entry. The below histogram produces a median salary roughly in line with what we would expect to see for data analytics roles, which confirms that we should proceed.

```{r}
USSalaries <- USSalaries %>% filter(USSalaries < 9999999)
quantile(USSalaries[[1]], na.rm = TRUE)
ggplot(USSalaries, aes(USSalaries[[1]])) + 
  geom_histogram(binwidth = 25000)
                                    
```

##Analysis of Skills by Salary, Job Satisfaction
The Kaggle dataset analyzes over 16,000 respondents from multiple countries. Are the most important skills the same across these variables?

###Time Spent by Skill by Salary

Limiting our data to responses by US\$ for comparison's sake,  we will perform an analysis of the previous survey response after creating a factor for respondents' salaries by quantile.

We will create levels from the numeric data using the ```cut``` function.
```{r}
USD <- Kaggle.Multi %>% 
  mutate(CompensationAmount = as.numeric(as.numeric(levels(CompensationAmount)[CompensationAmount])),
         CompensationAmount = ifelse(CompensationAmount < 100, CompensationAmount*1000, CompensationAmount)) %>%  
  filter(CompensationCurrency=="USD",
         CompensationAmount < 9999999) 

quantile(USD$CompensationAmount, na.rm = TRUE)
```
```{r}
#Create levels using cut()
USD <- USD %>% select(  
  TimeGatheringData,
  TimeModelBuilding,
  TimeProduction,
  TimeVisualizing,
  TimeFindingInsights,
  TimeOtherSelect,
  CompensationAmount) %>% 
  mutate(IncomeLevel = cut(x=CompensationAmount, breaks = c(0, 60000, 96000, 137500, 2500000))) 

levels(USD$IncomeLevel) <- c("Low", "Medium", "High", "Very_high")
```
```{r}
timeSpentByUSDSalary <- USD %>% 
  rename(
  'Gathering Data' = TimeGatheringData,
  'Modeling' = TimeModelBuilding,
  'Production' = TimeProduction,
  'Visualizing' = TimeVisualizing,
  'Finding Insights' = TimeFindingInsights,
  'Other' = TimeOtherSelect) %>% 
  gather(key="Skill", value="PercTimeSpent", -CompensationAmount, -IncomeLevel, na.rm = TRUE) 

timeSpentByUSDSalary%>% 
  group_by(Skill, IncomeLevel) %>% 
  summarize("avg" = mean(PercTimeSpent), "Median % Time Spent"= median(PercTimeSpent)) %>% 
  arrange(Skill, IncomeLevel) %>% 
  rename('Average % Time Spent' = avg) %>% 
  kable(digits = 0) %>% 
  kable_styling(bootstrap_options = "responsive")

```

These results are remarkably consistent across the income levels, althought the lowest earners seem to spend less time gathering data than other groups.
  

###Job Skills by Job Satisfaction

What about job satisfaction? Do more satisfied workers spend more time on certain parts of the job?

```{r}
timeSpentBySat <- Kaggle.Multi %>% select(  
    TimeGatheringData,
    TimeModelBuilding,
    TimeProduction,
    TimeVisualizing,
    TimeFindingInsights,
    TimeOtherSelect,
    JobSatisfaction) %>% 
  rename(
    'Gathering Data' = TimeGatheringData,
    'Modeling' = TimeModelBuilding,
    'Production' = TimeProduction,
    'Visualizing' = TimeVisualizing,
    'Finding Insights' = TimeFindingInsights,
    'Other' = TimeOtherSelect) %>% 
  gather(key="Skill", value="PercTimeSpent", -JobSatisfaction, na.rm = TRUE) %>% 
  mutate(JobSatisfaction = fct_recode(JobSatisfaction,
    "Low" = "1 - Highly Dissatisfied",
    "Low" = "2",
    "Low" = "3",
    "Medium" = "4",
    "Medium" = "5",
    "Medium" = "6",
    "Medium" = "7",
    "High" = "8",
    "High" = "9",
    "High" = "10 - Highly Satisfied",
    "NA" = "",
    "NA" = "I prefer not to share")) %>% 
  filter(!is.na(JobSatisfaction), 
         JobSatisfaction !="NA")

levels(timeSpentBySat$JobSatisfaction) <- c("NA", "Low", "Medium", "High")
```

```{r}
timeSpentBySat%>% 
  group_by(Skill, JobSatisfaction) %>% 
  summarize("avg" = mean(PercTimeSpent), "Median % Time Spent"= median(PercTimeSpent)) %>% 
  arrange(Skill, JobSatisfaction) %>% 
  rename('Average % Time Spent' = avg) %>% 
  kable(digits = 0) %>% 
  kable_styling(bootstrap_options = "responsive")

```

Interestingly, the least satisfied workers also seems to spend the most time gathering data!

